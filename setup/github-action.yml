# SaShip Daily Digest — GitHub Action
# Install this on the CLIENT DEV REPO (not the tracking repo).
#
# Required secrets (set on the client dev repo):
#   AI_GATEWAY_API_KEY   — Vercel AI Gateway API key for commit summarization
#   SLACK_WEBHOOK_URL    — Slack incoming webhook for daily digest
#   TRACKING_REPO_TOKEN  — GitHub PAT with repo write access to the tracking repo
#
# Required variables:
#   TRACKING_REPO        — e.g. "org/saship-tracking"
#   TRACKING_BRANCH      — e.g. "project-x"
#   COMMIT_PREFIX        — e.g. "[project-x]"

name: SaShip Daily Digest

on:
  schedule:
    - cron: "30 5 * * 1-5" # Weekdays at ~7:30 AM CET (5:30 UTC + GH Actions delay)
  workflow_dispatch: {}

permissions:
  contents: read

jobs:
  digest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout client repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Fetch all branches
        run: git fetch --all

      - name: Collect today's commits
        id: commits
        run: |
          SINCE=$(date -u -d "24 hours ago" +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v-24H +%Y-%m-%dT%H:%M:%SZ)
          PREFIX="${{ vars.COMMIT_PREFIX }}"
          echo "::group::Commit collection"
          echo "Looking for commits since $SINCE"

          # Get ALL commits from all branches (for the commit log page)
          ALL_RAW=$(git log --all --since="$SINCE" --pretty=format:'%H|%an|%s' || true)

          if [ -z "$ALL_RAW" ]; then
            echo "no_all_commits=true" >> "$GITHUB_OUTPUT"
            echo "no_commits=true" >> "$GITHUB_OUTPUT"
            echo "::warning::No commits found in the last 24h"
            echo "::endgroup::"
            exit 0
          fi

          echo "no_all_commits=false" >> "$GITHUB_OUTPUT"

          # Build JSON array for ALL commits (used by commit log page)
          echo "$ALL_RAW" | while IFS= read -r line; do
            HASH=$(echo "$line" | cut -d'|' -f1)
            AUTHOR=$(echo "$line" | cut -d'|' -f2)
            MESSAGE=$(echo "$line" | cut -d'|' -f3-)
            jq -n --arg h "$HASH" --arg a "$AUTHOR" --arg m "$MESSAGE" \
              '{hash:$h, author:$a, message:$m}'
          done | jq -s '.' > /tmp/all_commits.json

          ALL_COUNT=$(jq 'length' /tmp/all_commits.json)
          echo "Found $ALL_COUNT total commit(s)"

          echo "all_commits_json<<EOF" >> "$GITHUB_OUTPUT"
          cat /tmp/all_commits.json >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

          # Get prefix-filtered commits (for AI matching and MDX updates)
          COMMITS=$(echo "$ALL_RAW" | grep -F "$PREFIX" || true)

          if [ -z "$COMMITS" ]; then
            echo "no_commits=true" >> "$GITHUB_OUTPUT"
            echo "::warning::No commits with prefix $PREFIX found (but $ALL_COUNT total commits logged)"
            echo "::endgroup::"
            exit 0
          fi

          COMMIT_COUNT=$(echo "$COMMITS" | wc -l | tr -d ' ')
          echo "Found $COMMIT_COUNT prefixed commit(s)"
          echo "$COMMITS"
          echo "no_commits=false" >> "$GITHUB_OUTPUT"

          # Build JSON array of prefixed commits using jq for safe encoding
          echo "$COMMITS" | while IFS= read -r line; do
            HASH=$(echo "$line" | cut -d'|' -f1)
            AUTHOR=$(echo "$line" | cut -d'|' -f2)
            MESSAGE=$(echo "$line" | cut -d'|' -f3-)
            # Determine environment by checking which branches contain this commit
            ENV="staging"
            if git branch -a --contains "$HASH" 2>/dev/null | grep -qE "main$|master$|production$|remotes/origin/main$|remotes/origin/master$|remotes/origin/production$"; then
              ENV="prod"
            fi
            # Determine status from branch: main/production = deployed, staging = staging
            STATUS="staging"
            if [ "$ENV" = "prod" ]; then
              STATUS="deployed"
            fi
            jq -n --arg h "$HASH" --arg a "$AUTHOR" --arg m "$MESSAGE" --arg e "$ENV" --arg s "$STATUS" \
              '{hash:$h, author:$a, message:$m, env:$e, status:$s}'
          done | jq -s '.' > /tmp/commits.json

          echo "commits_json<<EOF" >> "$GITHUB_OUTPUT"
          cat /tmp/commits.json >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "Commits JSON:"
          cat /tmp/commits.json
          echo "::endgroup::"

      - name: Update commit log on tracking repo
        if: steps.commits.outputs.no_all_commits != 'true'
        env:
          TRACKING_REPO_TOKEN: ${{ secrets.TRACKING_REPO_TOKEN }}
          TRACKING_REPO: ${{ vars.TRACKING_REPO }}
          TRACKING_BRANCH: ${{ vars.TRACKING_BRANCH }}
          ALL_COMMITS_JSON: ${{ steps.commits.outputs.all_commits_json }}
        run: |
          TRACKING_REPO_TOKEN=$(printf '%s' "$TRACKING_REPO_TOKEN" | tr -d '\n\r')
          echo "::group::Update commit log"

          printenv ALL_COMMITS_JSON > /tmp/commits_for_log.json

          # Format commits as markdown bullet list, stripping the project prefix
          # Add a date heading so the frontend can group commits by day
          YESTERDAY=$(date -u -d "yesterday" +%Y-%m-%d 2>/dev/null || date -u -v-1d +%Y-%m-%d)
          TODAY_HEADING="### $YESTERDAY"
          BULLET_LIST=$(printf '%s\n%s' "$TODAY_HEADING" "$(jq -r '.[] | "- " + (.message | gsub("^\\[.*?\\] *"; "")) + " — *" + .author + "*"' /tmp/commits_for_log.json)")

          if [ -z "$BULLET_LIST" ]; then
            echo "No commits to add to commit log"
            echo "::endgroup::"
            exit 0
          fi

          COMMIT_COUNT=$(echo "$BULLET_LIST" | wc -l | tr -d ' ')
          echo "Adding $COMMIT_COUNT commit(s) to commit log"

          # Fetch current commits.mdx from tracking repo
          FILE_PATH="content/commits.mdx"
          EXISTING=$(curl -s \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/$FILE_PATH?ref=$TRACKING_BRANCH")

          SHA=$(echo "$EXISTING" | jq -r '.sha // empty')
          CURRENT_CONTENT=$(echo "$EXISTING" | jq -r '.content // empty' | base64 -d 2>/dev/null || true)

          if [ -n "$CURRENT_CONTENT" ]; then
            # Prepend new commits after the "## Commit Log" heading
            printf '%s\n' "$BULLET_LIST" > /tmp/new_commits.txt
            echo "$CURRENT_CONTENT" | sed '/^## Commit Log$/r /tmp/new_commits.txt' > /tmp/commits_updated.mdx
          else
            # Create the file from scratch
            printf '## Commit Log\n%s\n' "$BULLET_LIST" > /tmp/commits_updated.mdx
          fi

          # Push updated file
          B64=$(base64 -w 0 /tmp/commits_updated.mdx)
          jq -n --arg msg "[bot] update: commit-log $(date +%Y-%m-%d)" \
            --arg content "$B64" \
            --arg branch "$TRACKING_BRANCH" \
            --arg sha "$SHA" \
            'if $sha == "" then {message:$msg, content:$content, branch:$branch}
             else {message:$msg, content:$content, branch:$branch, sha:$sha} end' \
            > /tmp/commits_payload.json

          if GH_TOKEN="$TRACKING_REPO_TOKEN" gh api \
            -X PUT \
            "/repos/$TRACKING_REPO/contents/$FILE_PATH" \
            --input /tmp/commits_payload.json > /tmp/commits_response.json 2>&1; then
            echo "Updated $FILE_PATH with $COMMIT_COUNT new commit(s)"
          else
            echo "::error::Failed to update $FILE_PATH"
            cat /tmp/commits_response.json
          fi
          echo "::endgroup::"

      - name: Fetch roadmap context from tracking repo
        if: steps.commits.outputs.no_commits != 'true'
        id: roadmap
        env:
          TRACKING_REPO_TOKEN: ${{ secrets.TRACKING_REPO_TOKEN }}
          TRACKING_REPO: ${{ vars.TRACKING_REPO }}
          TRACKING_BRANCH: ${{ vars.TRACKING_BRANCH }}
        run: |
          echo "::group::Fetch roadmap context"

          # Fetch project.config.json
          CONFIG_RESP=$(curl -s \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/project.config.json?ref=$TRACKING_BRANCH")

          PROJECT_CONFIG=$(echo "$CONFIG_RESP" | jq -r '.content // empty' | base64 -d 2>/dev/null || echo '{}')
          echo "Project config fetched: $(echo "$PROJECT_CONFIG" | jq -r '.project // "unknown"')"

          # Fetch list of content/*.mdx files
          CONTENT_RESP=$(curl -s \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/content?ref=$TRACKING_BRANCH")

          # For each MDX file, fetch its frontmatter
          ROADMAP_ENTRIES="[]"
          for FILE_URL in $(echo "$CONTENT_RESP" | jq -r '.[]? | select(.name | endswith(".mdx") and .name != "commits.mdx") | .url'); do
            FILE_DATA=$(curl -s \
              -H "Authorization: token $TRACKING_REPO_TOKEN" \
              -H "Accept: application/vnd.github.v3+json" \
              "$FILE_URL?ref=$TRACKING_BRANCH")

            FILENAME=$(echo "$FILE_DATA" | jq -r '.name')
            SLUG="${FILENAME%.mdx}"
            FILE_CONTENT=$(echo "$FILE_DATA" | jq -r '.content // empty' | base64 -d 2>/dev/null || true)

            if [ -n "$FILE_CONTENT" ]; then
              # Extract frontmatter fields
              TITLE=$(echo "$FILE_CONTENT" | sed -n '/^---$/,/^---$/p' | grep '^title:' | sed 's/^title: *//')
              OWNER=$(echo "$FILE_CONTENT" | sed -n '/^---$/,/^---$/p' | grep '^owner:' | sed 's/^owner: *//')
              STATUS=$(echo "$FILE_CONTENT" | sed -n '/^---$/,/^---$/p' | grep '^status:' | sed 's/^status: *//')
              ENV=$(echo "$FILE_CONTENT" | sed -n '/^---$/,/^---$/p' | grep '^environment:' | sed 's/^environment: *//')

              ROADMAP_ENTRIES=$(echo "$ROADMAP_ENTRIES" | jq --arg s "$SLUG" --arg t "$TITLE" --arg o "$OWNER" --arg st "$STATUS" --arg e "$ENV" \
                '. + [{slug: $s, title: $t, owner: $o, status: $st, environment: $e}]')
            fi
          done

          echo "Found $(echo "$ROADMAP_ENTRIES" | jq 'length') existing roadmap entries"
          echo "$ROADMAP_ENTRIES" | jq '.'

          # Fetch content/roadmap.json (sprint plan — single source of truth for deliverables per dev)
          SCHEDULE_RESP=$(curl -s \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/content/roadmap.json?ref=$TRACKING_BRANCH")

          SCHEDULE=$(echo "$SCHEDULE_RESP" | jq -r '.content // empty' | base64 -d 2>/dev/null || echo '{"startDate":"","weeks":[]}')
          echo "Roadmap fetched: $(echo "$SCHEDULE" | jq '.weeks | length') weeks, startDate=$(echo "$SCHEDULE" | jq -r '.startDate')"

          # Fetch content/extras.json (additional developments)
          EXTRAS_RESP=$(curl -s \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/content/extras.json?ref=$TRACKING_BRANCH")

          EXTRAS=$(echo "$EXTRAS_RESP" | jq -r '.content // empty' | base64 -d 2>/dev/null || echo '[]')
          echo "Extras fetched: $(echo "$EXTRAS" | jq 'length') items"

          # Write to temp files for the next step (avoids shell quoting issues)
          echo "$PROJECT_CONFIG" > /tmp/project_config.json
          echo "$ROADMAP_ENTRIES" > /tmp/roadmap_entries.json
          echo "$SCHEDULE" > /tmp/schedule.json
          echo "$EXTRAS" > /tmp/extras.json

          echo "project_config<<EOF" >> "$GITHUB_OUTPUT"
          echo "$PROJECT_CONFIG" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

          echo "roadmap_entries<<EOF" >> "$GITHUB_OUTPUT"
          echo "$ROADMAP_ENTRIES" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

          echo "schedule<<EOF" >> "$GITHUB_OUTPUT"
          echo "$SCHEDULE" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

          echo "extras<<EOF" >> "$GITHUB_OUTPUT"
          echo "$EXTRAS" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

          echo "::endgroup::"

      - name: Summarize with AI Gateway
        if: steps.commits.outputs.no_commits != 'true'
        id: summary
        env:
          AI_GATEWAY_API_KEY: ${{ secrets.AI_GATEWAY_API_KEY }}
        run: |
          TODAY=$(date +%Y-%m-%d)
          YESTERDAY=$(date -u -d "yesterday" +%Y-%m-%d 2>/dev/null || date -u -v-1d +%Y-%m-%d)

          # Write commits, config, roadmap, and schedule to temp files (already there from previous steps)
          echo '${{ steps.commits.outputs.commits_json }}' > /tmp/commits_input.json
          echo '${{ steps.roadmap.outputs.project_config }}' > /tmp/config_input.json
          echo '${{ steps.roadmap.outputs.roadmap_entries }}' > /tmp/roadmap_input.json
          echo '${{ steps.roadmap.outputs.schedule }}' > /tmp/schedule_input.json
          echo '${{ steps.roadmap.outputs.extras }}' > /tmp/extras_input.json

          COMMITS=$(cat /tmp/commits_input.json)
          CONFIG=$(cat /tmp/config_input.json)
          ROADMAP=$(cat /tmp/roadmap_input.json)
          SCHEDULE=$(cat /tmp/schedule_input.json)
          EXTRAS=$(cat /tmp/extras_input.json)

          # Build the prompt as a file to avoid shell quoting issues
          cat > /tmp/ai_prompt.txt <<PROMPT_EOF
          Tu es un assistant de suivi de livraisons pour un projet SaaS. Tu as le contexte complet de la roadmap du projet.

          CONFIGURATION DU PROJET :
          $CONFIG

          PLANNING DES SPRINTS (livrables par dev par semaine — source unique de verite) :
          $SCHEDULE

          LIVRABLES EXISTANTS DE LA ROADMAP (etat actuel des fichiers MDX) :
          $ROADMAP

          COMMITS DU JOUR :
          $COMMITS

          DEVELOPPEMENTS SUPPLEMENTAIRES (demandes client hors roadmap) :
          $EXTRAS

          INSTRUCTIONS :
          1. Associe chaque commit a un livrable EXISTANT de la roadmap en utilisant le slug exact des entrees roadmap ci-dessus.
          2. Si un commit correspond clairement a un livrable du PLANNING DES SPRINTS qui n'a PAS encore de fichier MDX, cree une nouvelle entree en suivant la convention : kebab-case-titre-prenomdev (ex: "finances-ai-onboarding-wizard-leonard").
          3. Si un commit ne correspond clairement a AUCUN livrable, IGNORE-LE — ne force pas d'association. Inclus-le uniquement dans le digest Slack sous une section "Autres changements".
          4. NE determine PAS le statut toi-meme. Chaque commit a deja un champ "status" derive de sa branche (staging = "staging", main/production = "deployed"). Utilise cette valeur telle quelle.
          5. Pour le champ "owner", utilise TOUJOURS le prenom exact tel qu'il apparait dans le PLANNING DES SPRINTS, PAS le nom complet de l'auteur du commit git. Fais correspondre l'auteur du commit au dev le plus proche dans le planning.
          6. Pour le champ "title" des NOUVEAUX fichiers, utilise EXACTEMENT le titre tel qu'il apparait dans le PLANNING DES SPRINTS. Ne traduis pas et n'invente pas de titre different.
          7. Ecris une entree de changelog EN FRANCAIS pour chaque livrable associe. N'inclus PAS le nom de l'auteur dans l'entree (le owner est deja dans le frontmatter et affiche par colonne). Format :
             ### $TODAY
             <resume concis en francais>
          8. Ecris un digest Slack quotidien EN FRANCAIS groupe par developpeur, puis par environnement. Utilise du francais simple, pas les messages de commit bruts. Pour le gras, utilise *simple asterisques* (format Slack mrkdwn), JAMAIS **double asterisques**. IMPORTANT : N'utilise PAS de termes techniques comme [PROD], [STAGING], [DEV]. Utilise des termes simples : pour prod/deployed ecris "En production", pour staging ecris "En validation (staging)", pour dev ecris "En développement". Le titre du message doit etre "Suivi des livraisons — $YESTERDAY" (utilise la date d'HIER, pas d'aujourd'hui, car les commits rapportes sont ceux de la veille). En bas du message, ecris "X changement(s) livré(s) hier" (PAS "aujourd'hui").
          9. Si un commit resout ou complete clairement un element des DEVELOPPEMENTS SUPPLEMENTAIRES, inclus-le dans "extras_updates" avec l'"id" exact de l'element et le statut "done". Ne marque comme done que si le commit traite reellement l'extra — ne force pas d'associations.

          Reponds au format JSON :
          {
            "slack_message": "<digest formate en slack markdown, en francais>",
            "mdx_updates": [
              {
                "deliverable_slug": "<slug exact de la roadmap ou nouveau slug kebab-case>",
                "title": "<titre du livrable — uniquement pour les nouveaux fichiers>",
                "owner": "<prenom exact du dev depuis le planning>",
                "environment": "<staging|prod du commit>",
                "status": "<staging|deployed du commit>",
                "entry": "### $TODAY\n<resume en francais>"
              }
            ],
            "extras_updates": [
              {
                "id": "<id exact de l'extra>",
                "status": "done"
              }
            ]
          }

          Si aucun commit ne correspond a un livrable, renvoie un tableau mdx_updates vide.
          Si aucun commit ne resout un extra, renvoie un tableau extras_updates vide.
          PROMPT_EOF

          echo "::group::AI Gateway request"
          echo "Calling AI Gateway (model: anthropic/claude-haiku-4-5)"

          # Use jq to safely encode the prompt into JSON
          PROMPT_CONTENT=$(cat /tmp/ai_prompt.txt)
          jq -n --arg content "$PROMPT_CONTENT" '{
            model: "anthropic/claude-haiku-4-5",
            max_tokens: 2048,
            messages: [{role: "user", content: $content}]
          }' > /tmp/ai_request.json

          HTTP_CODE=$(curl -s -o /tmp/ai_response.json -w "%{http_code}" \
            https://ai-gateway.vercel.sh/v1/chat/completions \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $AI_GATEWAY_API_KEY" \
            -d @/tmp/ai_request.json)

          RESPONSE=$(cat /tmp/ai_response.json)
          echo "AI Gateway HTTP status: $HTTP_CODE"

          if [ "$HTTP_CODE" != "200" ]; then
            echo "::error::AI Gateway returned HTTP $HTTP_CODE"
            echo "Response body: $RESPONSE"
            echo "::endgroup::"
            exit 1
          fi

          # Extract the text content (OpenAI-compatible response format)
          CONTENT=$(echo "$RESPONSE" | jq -r '.choices[0].message.content')

          if [ -z "$CONTENT" ] || [ "$CONTENT" = "null" ]; then
            echo "::error::AI Gateway returned empty content"
            echo "Raw response: $RESPONSE"
            echo "::endgroup::"
            exit 1
          fi

          echo "AI Gateway response received (${#CONTENT} chars)"
          echo "::endgroup::"

          echo "response<<EOF" >> "$GITHUB_OUTPUT"
          echo "$CONTENT" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

      - name: Post to Slack
        if: steps.commits.outputs.no_commits != 'true'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          RESPONSE='${{ steps.summary.outputs.response }}'
          SLACK_MSG=$(echo "$RESPONSE" | jq -r '.slack_message // empty')
          # Append SaShip tracking link
          SLACK_MSG=$(printf '%s\n\n<https://eos.saship.42lab.co/|Voir l'\''avancée sur SaShip>' "$SLACK_MSG")

          if [ -z "$SLACK_MSG" ]; then
            echo "::warning::No slack_message found in AI response — skipping Slack post"
            exit 0
          fi

          echo "::group::Slack post"
          SLACK_HTTP=$(curl -s -o /tmp/slack_response.txt -w "%{http_code}" \
            -X POST "$SLACK_WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -d "{\"text\": $(echo "$SLACK_MSG" | jq -Rs .)}")

          echo "Slack HTTP status: $SLACK_HTTP"
          if [ "$SLACK_HTTP" != "200" ]; then
            echo "::error::Slack webhook returned HTTP $SLACK_HTTP"
            cat /tmp/slack_response.txt
          else
            echo "Slack digest posted successfully"
          fi
          echo "::endgroup::"

      - name: Update tracking repo MDX files
        if: steps.commits.outputs.no_commits != 'true'
        env:
          TRACKING_REPO_TOKEN: ${{ secrets.TRACKING_REPO_TOKEN }}
          TRACKING_REPO: ${{ vars.TRACKING_REPO }}
          TRACKING_BRANCH: ${{ vars.TRACKING_BRANCH }}
        run: |
          RESPONSE='${{ steps.summary.outputs.response }}'

          UPDATE_COUNT=$(echo "$RESPONSE" | jq '.mdx_updates | length')
          echo "::group::MDX updates ($UPDATE_COUNT file(s))"

          if [ "$UPDATE_COUNT" = "0" ]; then
            echo "No deliverable updates — all commits were unmatched"
            echo "::endgroup::"
            exit 0
          fi

          echo "$RESPONSE" | jq -c '.mdx_updates[]' | while read -r update; do
            SLUG=$(echo "$update" | jq -r '.deliverable_slug')
            ENTRY=$(echo "$update" | jq -r '.entry')
            OWNER=$(echo "$update" | jq -r '.owner')
            ENV=$(echo "$update" | jq -r '.environment')
            STATUS=$(echo "$update" | jq -r '.status')
            TITLE=$(echo "$update" | jq -r '.title // empty')
            FILE_PATH="content/${SLUG}.mdx"

            echo "--- Updating $FILE_PATH on $TRACKING_REPO@$TRACKING_BRANCH (status=$STATUS, env=$ENV, owner=$OWNER)"

            # Get current file content (if exists)
            EXISTING=$(curl -s \
              -H "Authorization: token $TRACKING_REPO_TOKEN" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/$TRACKING_REPO/contents/$FILE_PATH?ref=$TRACKING_BRANCH")

            SHA=$(echo "$EXISTING" | jq -r '.sha // empty')
            CURRENT_CONTENT=$(echo "$EXISTING" | jq -r '.content // empty' | base64 -d 2>/dev/null || true)

            if [ -n "$CURRENT_CONTENT" ]; then
              # Prepend new entry after "## Changelog" line
              NEW_CONTENT=$(echo "$CURRENT_CONTENT" | awk -v entry="$ENTRY" '/^## Changelog$/{print; print ""; print entry; next}1')
              # Update frontmatter status and environment
              NEW_CONTENT=$(echo "$NEW_CONTENT" | sed "s/^status: .*/status: $STATUS/")
              NEW_CONTENT=$(echo "$NEW_CONTENT" | sed "s/^environment: .*/environment: $ENV/")
            else
              # Create new file — use title from AI response or derive from slug
              if [ -z "$TITLE" ]; then
                TITLE=$(echo "$SLUG" | sed 's/-/ /g' | awk '{for(i=1;i<=NF;i++) $i=toupper(substr($i,1,1)) tolower(substr($i,2))}1')
              fi
              NEW_CONTENT=$(printf '%s\n%s\n%s\n%s\n%s\n%s\n\n%s\n\n%s' \
                "---" \
                "title: $TITLE" \
                "owner: $OWNER" \
                "status: $STATUS" \
                "environment: $ENV" \
                "---" \
                "## Changelog" \
                "$ENTRY")
            fi

            # Validate MDX (basic check — ensure frontmatter is intact)
            if ! echo "$NEW_CONTENT" | head -1 | grep -q "^---$"; then
              echo "ERROR: Invalid MDX for $SLUG — skipping"
              continue
            fi

            # Commit to tracking repo
            ENCODED=$(echo "$NEW_CONTENT" | base64 | tr -d '\n')

            PAYLOAD=$(jq -n --arg msg "[bot] update: $SLUG digest $(date +%Y-%m-%d)" \
              --arg content "$ENCODED" \
              --arg branch "$TRACKING_BRANCH" \
              --arg sha "$SHA" \
              'if $sha == "" then {message:$msg, content:$content, branch:$branch}
               else {message:$msg, content:$content, branch:$branch, sha:$sha} end')

            MDX_HTTP=$(curl -s -o /tmp/mdx_response.json -w "%{http_code}" -X PUT \
              -H "Authorization: token $TRACKING_REPO_TOKEN" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/$TRACKING_REPO/contents/$FILE_PATH" \
              -d "$PAYLOAD")

            if [ "$MDX_HTTP" = "200" ] || [ "$MDX_HTTP" = "201" ]; then
              echo "Updated $FILE_PATH (HTTP $MDX_HTTP)"
            else
              echo "::error::Failed to update $FILE_PATH (HTTP $MDX_HTTP)"
              cat /tmp/mdx_response.json
            fi
          done
          echo "::endgroup::"

      - name: Update extras.json on tracking repo
        if: steps.commits.outputs.no_commits != 'true'
        continue-on-error: true
        env:
          TRACKING_REPO_TOKEN: ${{ secrets.TRACKING_REPO_TOKEN }}
          TRACKING_REPO: ${{ vars.TRACKING_REPO }}
          TRACKING_BRANCH: ${{ vars.TRACKING_BRANCH }}
        run: |
          TRACKING_REPO_TOKEN=$(printf '%s' "$TRACKING_REPO_TOKEN" | tr -d '\n\r')
          RESPONSE='${{ steps.summary.outputs.response }}'
          echo "::group::Extras update"

          EXTRAS_COUNT=$(echo "$RESPONSE" | jq '.extras_updates // [] | length')

          if [ "$EXTRAS_COUNT" = "0" ] || [ "$EXTRAS_COUNT" = "null" ]; then
            echo "No extras updates"
            echo "::endgroup::"
            exit 0
          fi

          echo "Processing $EXTRAS_COUNT extras update(s)"

          # Fetch current extras.json
          FILE_PATH="content/extras.json"
          EXISTING=$(curl -s \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/$FILE_PATH?ref=$TRACKING_BRANCH")

          SHA=$(echo "$EXISTING" | jq -r '.sha // empty')
          CURRENT=$(echo "$EXISTING" | jq -r '.content // empty' | base64 -d 2>/dev/null || echo '[]')

          # Apply status updates from AI response
          UPDATED="$CURRENT"
          echo "$RESPONSE" | jq -c '.extras_updates // [] | .[]' | while read -r update; do
            EID=$(echo "$update" | jq -r '.id')
            ESTATUS=$(echo "$update" | jq -r '.status')
            echo "  Marking extra '$EID' as $ESTATUS"
            UPDATED=$(echo "$UPDATED" | jq --arg id "$EID" --arg status "$ESTATUS" \
              'map(if .id == $id then .status = $status else . end)')
            echo "$UPDATED" > /tmp/extras_updated.json
          done

          # Read the final result (the while loop runs in a subshell)
          if [ ! -f /tmp/extras_updated.json ]; then
            echo "No changes applied"
            echo "::endgroup::"
            exit 0
          fi

          UPDATED=$(cat /tmp/extras_updated.json)

          # Push updated extras.json
          ENCODED=$(echo "$UPDATED" | jq -c '.' | base64 | tr -d '\n')

          PAYLOAD=$(jq -n --arg msg "[bot] update: extras $(date +%Y-%m-%d)" \
            --arg content "$ENCODED" \
            --arg branch "$TRACKING_BRANCH" \
            --arg sha "$SHA" \
            'if $sha == "" then {message:$msg, content:$content, branch:$branch}
             else {message:$msg, content:$content, branch:$branch, sha:$sha} end')

          EXTRAS_HTTP=$(curl -s -o /tmp/extras_response.json -w "%{http_code}" -X PUT \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/$FILE_PATH" \
            -d "$PAYLOAD")

          if [ "$EXTRAS_HTTP" = "200" ] || [ "$EXTRAS_HTTP" = "201" ]; then
            echo "Updated $FILE_PATH (HTTP $EXTRAS_HTTP)"
          else
            echo "::error::Failed to update $FILE_PATH (HTTP $EXTRAS_HTTP)"
            cat /tmp/extras_response.json
          fi
          echo "::endgroup::"

      - name: Update stats.json with lines per dev
        if: steps.commits.outputs.no_commits != 'true'
        env:
          TRACKING_REPO_TOKEN: ${{ secrets.TRACKING_REPO_TOKEN }}
          TRACKING_REPO: ${{ vars.TRACKING_REPO }}
          TRACKING_BRANCH: ${{ vars.TRACKING_BRANCH }}
        run: |
          echo '${{ steps.commits.outputs.commits_json }}' > /tmp/commits_stats.json
          COMMITS=$(cat /tmp/commits_stats.json)
          echo "::group::Stats update"

          # Count lines added per author from today's commits
          LINES_TODAY=$(echo "$COMMITS" | jq -r '.[] | .author + "|" + .hash' | while read -r entry; do
            AUTHOR=$(echo "$entry" | cut -d'|' -f1)
            HASH=$(echo "$entry" | cut -d'|' -f2)
            ADDED=$(git show --stat "$HASH" 2>/dev/null | tail -1 | grep -oE '[0-9]+ insertion' | grep -oE '[0-9]+' || echo 0)
            echo "$AUTHOR|$ADDED"
          done | awk -F'|' '{a[$1]+=$2} END {for(k in a) printf "%s|%d\n",k,a[k]}')

          # Get current stats.json
          EXISTING=$(curl -s \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/stats.json?ref=$TRACKING_BRANCH")

          SHA=$(echo "$EXISTING" | jq -r '.sha // empty')
          CURRENT=$(echo "$EXISTING" | jq -r '.content // empty' | base64 -d 2>/dev/null || echo '{"daily":[],"lastUpdated":""}')

          # Build today's daily entry: {"date":"2026-02-18","Quentin":150,"Leonard":200}
          TODAY=$(date +%Y-%m-%d)
          echo '{}' | jq --arg d "$TODAY" '{date: $d}' > /tmp/today_entry.json

          while IFS='|' read -r dev lines; do
            [ -z "$dev" ] && continue
            jq --arg d "$dev" --argjson l "$lines" '.[$d] = $l' /tmp/today_entry.json > /tmp/today_tmp.json \
              && mv /tmp/today_tmp.json /tmp/today_entry.json
          done <<< "$LINES_TODAY"

          # Append today's entry to daily array (replace if same date exists) and update lastUpdated
          ENTRY=$(cat /tmp/today_entry.json)
          echo "$CURRENT" | jq --argjson entry "$ENTRY" --arg date "$TODAY" \
            '(.daily | map(select(.date != $date))) + [$entry] | {daily: ., lastUpdated: $date}' \
            > /tmp/stats_updated.json

          # Push updated stats.json
          ENCODED=$(jq -c '.' /tmp/stats_updated.json | base64 | tr -d '\n')

          PAYLOAD=$(jq -n --arg msg "[bot] stats: update $(date +%Y-%m-%d)" \
            --arg content "$ENCODED" \
            --arg branch "$TRACKING_BRANCH" \
            --arg sha "$SHA" \
            'if $sha == "" then {message:$msg, content:$content, branch:$branch}
             else {message:$msg, content:$content, branch:$branch, sha:$sha} end')

          STATS_HTTP=$(curl -s -o /tmp/stats_response.json -w "%{http_code}" -X PUT \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/stats.json" \
            -d "$PAYLOAD")

          if [ "$STATS_HTTP" = "200" ] || [ "$STATS_HTTP" = "201" ]; then
            echo "Updated stats.json (HTTP $STATS_HTTP)"
          else
            echo "::error::Failed to update stats.json (HTTP $STATS_HTTP)"
            cat /tmp/stats_response.json
          fi
          echo "::endgroup::"

      - name: Update sync log
        if: steps.commits.outputs.no_commits != 'true'
        env:
          TRACKING_REPO_TOKEN: ${{ secrets.TRACKING_REPO_TOKEN }}
          TRACKING_REPO: ${{ vars.TRACKING_REPO }}
          TRACKING_BRANCH: ${{ vars.TRACKING_BRANCH }}
        run: |
          echo "::group::Sync log update"
          NOW=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          TODAY=$(date +%Y-%m-%d)

          RESPONSE='${{ steps.summary.outputs.response }}'
          COMMIT_COUNT=$(echo '${{ steps.commits.outputs.commits_json }}' | jq 'length')
          MDX_COUNT=$(echo "$RESPONSE" | jq '.mdx_updates | length')
          FILES_TOUCHED=$(echo "$RESPONSE" | jq -r '[.mdx_updates[].deliverable_slug] | join(", ")')

          # Get current sync-log.json
          EXISTING=$(curl -s \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/sync-log.json?ref=$TRACKING_BRANCH")

          SHA=$(echo "$EXISTING" | jq -r '.sha // empty')
          CURRENT=$(echo "$EXISTING" | jq -r '.content // empty' | base64 -d 2>/dev/null || echo '{"lastSync":"","runs":[]}')

          # Build new run entry
          NEW_RUN=$(jq -n \
            --arg ts "$NOW" \
            --argjson commits "$COMMIT_COUNT" \
            --argjson mdx "$MDX_COUNT" \
            --arg files "$FILES_TOUCHED" \
            '{timestamp: $ts, commitsProcessed: $commits, filesUpdated: $mdx, deliverables: $files}')

          # Append run (keep last 30 entries) and update lastSync
          UPDATED=$(echo "$CURRENT" | jq --argjson run "$NEW_RUN" --arg ts "$NOW" \
            '{lastSync: $ts, runs: ([.runs[], $run] | .[-30:])}')

          ENCODED=$(echo "$UPDATED" | jq -c '.' | base64 | tr -d '\n')

          PAYLOAD=$(jq -n --arg msg "[bot] sync-log: $TODAY" \
            --arg content "$ENCODED" \
            --arg branch "$TRACKING_BRANCH" \
            --arg sha "$SHA" \
            'if $sha == "" then {message:$msg, content:$content, branch:$branch}
             else {message:$msg, content:$content, branch:$branch, sha:$sha} end')

          LOG_HTTP=$(curl -s -o /tmp/log_response.json -w "%{http_code}" -X PUT \
            -H "Authorization: token $TRACKING_REPO_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$TRACKING_REPO/contents/sync-log.json" \
            -d "$PAYLOAD")

          if [ "$LOG_HTTP" = "200" ] || [ "$LOG_HTTP" = "201" ]; then
            echo "Updated sync-log.json (HTTP $LOG_HTTP)"
          else
            echo "::error::Failed to update sync-log.json (HTTP $LOG_HTTP)"
            cat /tmp/log_response.json
          fi
          echo "::endgroup::"
